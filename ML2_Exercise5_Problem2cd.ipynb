{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:0.25122714042663574\n",
      "epoch:1, loss:0.39105406403541565\n",
      "Training data Accuracy: 57288/60000 = 0.955\n",
      "testing data Accuracy: 9547/10000 = 0.955\n",
      "type(Hv): <class 'tuple'>\n",
      "shape of Hv:  8\n",
      "layer  0  :  torch.Size([64, 784])\n",
      "layer  1  :  torch.Size([64])\n",
      "layer  2  :  torch.Size([64, 64])\n",
      "layer  3  :  torch.Size([64])\n",
      "layer  4  :  torch.Size([64, 64])\n",
      "layer  5  :  torch.Size([64])\n",
      "layer  6  :  torch.Size([10, 64])\n",
      "layer  7  :  torch.Size([10])\n",
      "Hv: (tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([ 0.0646,  0.0502,  0.2090, -0.1409,  0.0000,  0.1885,  0.1577, -0.0390,\n",
      "        -0.1372,  0.2511,  0.0000,  0.0000, -0.1839, -0.1546, -0.1337, -0.2746,\n",
      "        -0.0957,  0.2468,  0.2163,  0.0000,  0.0461,  0.0760,  0.0000,  0.0000,\n",
      "         0.0689,  0.1481,  0.3257, -0.0774,  0.2107,  0.1809,  0.1768, -0.0255,\n",
      "         0.0000, -0.1450,  0.1416,  0.0000, -0.1030,  0.0000,  0.0000, -0.1164,\n",
      "        -0.1561,  0.0000,  0.0000,  0.0548,  0.0000,  0.0000, -0.0998,  0.0306,\n",
      "         0.0619,  0.0807, -0.1007,  0.0809, -0.2181,  0.0000,  0.0546,  0.0000,\n",
      "        -0.0281, -0.1188,  0.0000,  0.2331, -0.0762, -0.0471,  0.0559,  0.0943]), tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0280,  0.0267,  0.0192,  ...,  0.0027,  0.0434,  0.0483],\n",
      "        [-0.2640, -0.2532, -0.1841,  ..., -0.0359, -0.4021, -0.4493],\n",
      "        ...,\n",
      "        [ 0.1653,  0.1587,  0.1158,  ...,  0.0240,  0.2508,  0.2804],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), tensor([ 0.0000,  0.0245, -0.2209,  0.1566,  0.0000,  0.0594,  0.1073,  0.0000,\n",
      "         0.1718,  0.0000, -0.0580,  0.0000,  0.1082,  0.0000,  0.1668, -0.1067,\n",
      "        -0.1961, -0.0277,  0.0000,  0.0000, -0.1117,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0902, -0.1531,  0.0000, -0.0203,  0.0000,  0.2039,  0.1492,  0.0000,\n",
      "        -0.1433, -0.0463,  0.0000, -0.0242,  0.2014,  0.0989,  0.0000,  0.0000,\n",
      "        -0.0522,  0.1425,  0.0584,  0.0000, -0.0653,  0.0000,  0.0000,  0.0122,\n",
      "         0.0000,  0.0352,  0.0000,  0.0000,  0.0036,  0.0000,  0.0000,  0.2018,\n",
      "        -0.0228,  0.1262,  0.1107, -0.0061, -0.1735,  0.1367,  0.0000,  0.0000]), tensor([[ 0.0000,  0.4322,  0.0172,  ...,  0.1336,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.2977, -0.0122,  ..., -0.0921,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0660, -0.0021,  ..., -0.0202,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.3906,  0.0165,  ...,  0.1210,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), tensor([ 0.1162, -0.0797,  0.0000, -0.1845, -0.0223,  0.0000,  0.0000, -0.0666,\n",
      "         0.0000,  0.0000,  0.0000, -0.1487,  0.0704,  0.0000, -0.0444,  0.0000,\n",
      "         0.0000,  0.0751,  0.0000,  0.0995,  0.0004,  0.0000,  0.1732,  0.1253,\n",
      "         0.0108,  0.0099,  0.1984,  0.0000,  0.0000, -0.0608,  0.0000,  0.1902,\n",
      "         0.1684,  0.0000,  0.0000, -0.0251, -0.0118,  0.0000,  0.0978,  0.0000,\n",
      "         0.0000,  0.0836, -0.0091, -0.2055,  0.0000,  0.0067,  0.0664,  0.1400,\n",
      "         0.0000, -0.1011, -0.0830,  0.0198, -0.0574,  0.0084,  0.0000,  0.0000,\n",
      "         0.0309,  0.0000, -0.0789,  0.0992,  0.0000, -0.0181,  0.1042,  0.0000]), tensor([[-1.1358e-01, -2.8821e-03,  0.0000e+00, -1.0085e-02, -1.2761e-01,\n",
      "          0.0000e+00,  0.0000e+00, -2.4677e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.5298e-02, -9.0116e-02,  0.0000e+00, -4.2481e-02,\n",
      "          0.0000e+00,  0.0000e+00, -5.9550e-02,  0.0000e+00, -7.2962e-02,\n",
      "         -5.3338e-02,  0.0000e+00, -6.8707e-02, -7.7819e-02, -8.0325e-03,\n",
      "         -2.4530e-02, -1.9677e-02,  0.0000e+00,  0.0000e+00, -8.1394e-03,\n",
      "          0.0000e+00, -9.7050e-02, -9.8823e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0486e-01, -1.0754e-01,  0.0000e+00, -1.2438e-01,  0.0000e+00,\n",
      "          0.0000e+00, -1.1711e-01, -1.8834e-02, -1.5719e-02,  0.0000e+00,\n",
      "         -2.8542e-02, -4.9406e-02, -3.7608e-02,  0.0000e+00, -1.0932e-01,\n",
      "         -1.1239e-02, -1.3266e-01, -8.9222e-02, -4.8546e-02,  0.0000e+00,\n",
      "          0.0000e+00, -4.7862e-02,  0.0000e+00, -2.1431e-02, -1.6491e-02,\n",
      "          0.0000e+00, -5.6615e-03, -8.0902e-02,  0.0000e+00],\n",
      "        [-9.6694e-03, -3.6401e-04,  0.0000e+00, -1.0462e-03, -1.0854e-02,\n",
      "          0.0000e+00,  0.0000e+00, -2.1357e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.2630e-03, -7.7099e-03,  0.0000e+00, -3.6662e-03,\n",
      "          0.0000e+00,  0.0000e+00, -5.0816e-03,  0.0000e+00, -6.1700e-03,\n",
      "         -4.6004e-03,  0.0000e+00, -5.8595e-03, -6.5699e-03, -8.3994e-04,\n",
      "         -2.0969e-03, -1.7208e-03,  0.0000e+00,  0.0000e+00, -8.1926e-04,\n",
      "          0.0000e+00, -8.1640e-03, -8.4368e-03,  0.0000e+00,  0.0000e+00,\n",
      "         -8.9817e-03, -9.1964e-03,  0.0000e+00, -1.0547e-02,  0.0000e+00,\n",
      "          0.0000e+00, -9.9657e-03, -1.5864e-03, -1.4176e-03,  0.0000e+00,\n",
      "         -2.5051e-03, -4.2165e-03, -3.2128e-03,  0.0000e+00, -9.3067e-03,\n",
      "         -1.1691e-03, -1.1305e-02, -7.6105e-03, -4.2085e-03,  0.0000e+00,\n",
      "          0.0000e+00, -4.0663e-03,  0.0000e+00, -1.8904e-03, -1.4196e-03,\n",
      "          0.0000e+00, -5.4642e-04, -6.8378e-03,  0.0000e+00],\n",
      "        [-1.3587e+00,  4.1116e-02,  0.0000e+00, -1.1219e-03, -1.5326e+00,\n",
      "          0.0000e+00,  0.0000e+00, -2.7293e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -2.3296e-01, -1.0536e+00,  0.0000e+00, -4.7644e-01,\n",
      "          0.0000e+00,  0.0000e+00, -7.0460e-01,  0.0000e+00, -8.9908e-01,\n",
      "         -5.9999e-01,  0.0000e+00, -8.1521e-01, -9.6575e-01,  3.3762e-03,\n",
      "         -2.8786e-01, -2.0622e-01,  0.0000e+00,  0.0000e+00, -1.6871e-02,\n",
      "          0.0000e+00, -1.2233e+00, -1.1669e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.2195e+00, -1.2599e+00,  0.0000e+00, -1.5144e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.4036e+00, -2.3609e-01, -1.3742e-01,  0.0000e+00,\n",
      "         -2.9345e-01, -5.8432e-01, -4.4272e-01,  0.0000e+00, -1.3074e+00,\n",
      "          8.3196e-04, -1.5796e+00, -1.0577e+00, -5.3240e-01,  0.0000e+00,\n",
      "          0.0000e+00, -5.7775e-01,  0.0000e+00, -2.1432e-01, -1.8725e-01,\n",
      "          0.0000e+00, -2.6666e-02, -9.9925e-01,  0.0000e+00],\n",
      "        [-9.0492e-01,  4.0576e-02,  0.0000e+00,  2.0112e-02, -1.0218e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.7789e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.4300e-01, -6.9741e-01,  0.0000e+00, -3.1177e-01,\n",
      "          0.0000e+00,  0.0000e+00, -4.6792e-01,  0.0000e+00, -6.0338e-01,\n",
      "         -3.9295e-01,  0.0000e+00, -5.4176e-01, -6.4928e-01,  1.9607e-02,\n",
      "         -1.9075e-01, -1.3226e-01,  0.0000e+00,  0.0000e+00,  2.8120e-03,\n",
      "          0.0000e+00, -8.2558e-01, -7.7447e-01,  0.0000e+00,  0.0000e+00,\n",
      "         -8.0609e-01, -8.3447e-01,  0.0000e+00, -1.0132e+00,  0.0000e+00,\n",
      "          0.0000e+00, -9.3530e-01, -1.5912e-01, -8.2685e-02,  0.0000e+00,\n",
      "         -1.8707e-01, -3.8799e-01, -2.9361e-01,  0.0000e+00, -8.7070e-01,\n",
      "          2.4163e-02, -1.0508e+00, -7.0274e-01, -3.4615e-01,  0.0000e+00,\n",
      "          0.0000e+00, -3.8569e-01,  0.0000e+00, -1.3540e-01, -1.2296e-01,\n",
      "          0.0000e+00, -1.0594e-02, -6.7100e-01,  0.0000e+00],\n",
      "        [-5.4234e-03, -2.3213e-04,  0.0000e+00, -6.3098e-04, -6.0856e-03,\n",
      "          0.0000e+00,  0.0000e+00, -1.2061e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.2950e-03, -4.3334e-03,  0.0000e+00, -2.0680e-03,\n",
      "          0.0000e+00,  0.0000e+00, -2.8531e-03,  0.0000e+00, -3.4509e-03,\n",
      "         -2.5943e-03,  0.0000e+00, -3.2890e-03, -3.6720e-03, -5.0790e-04,\n",
      "         -1.1782e-03, -9.7597e-04,  0.0000e+00,  0.0000e+00, -4.8928e-04,\n",
      "          0.0000e+00, -4.5559e-03, -4.7377e-03,  0.0000e+00,  0.0000e+00,\n",
      "         -5.0505e-03, -5.1679e-03,  0.0000e+00, -5.9056e-03,  0.0000e+00,\n",
      "          0.0000e+00, -5.5886e-03, -8.8578e-04, -8.1385e-04,  0.0000e+00,\n",
      "         -1.4228e-03, -2.3674e-03, -1.8046e-03,  0.0000e+00, -5.2201e-03,\n",
      "         -7.0579e-04, -6.3434e-03, -4.2721e-03, -2.3783e-03,  0.0000e+00,\n",
      "          0.0000e+00, -2.2788e-03,  0.0000e+00, -1.0759e-03, -7.9991e-04,\n",
      "          0.0000e+00, -3.2166e-04, -3.8235e-03,  0.0000e+00],\n",
      "        [-7.2064e-02, -2.2393e-03,  0.0000e+00, -7.0480e-03, -8.0931e-02,\n",
      "          0.0000e+00,  0.0000e+00, -1.5778e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.6429e-02, -5.7307e-02,  0.0000e+00, -2.7125e-02,\n",
      "          0.0000e+00,  0.0000e+00, -3.7824e-02,  0.0000e+00, -4.6148e-02,\n",
      "         -3.4047e-02,  0.0000e+00, -4.3628e-02, -4.9183e-02, -5.6367e-03,\n",
      "         -1.5593e-02, -1.2642e-02,  0.0000e+00,  0.0000e+00, -5.6014e-03,\n",
      "          0.0000e+00, -6.1235e-02, -6.2782e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -6.6720e-02, -6.8372e-02,  0.0000e+00, -7.8768e-02,  0.0000e+00,\n",
      "          0.0000e+00, -7.4289e-02, -1.1891e-02, -1.0248e-02,  0.0000e+00,\n",
      "         -1.8370e-02, -3.1382e-02, -2.3899e-02,  0.0000e+00, -6.9359e-02,\n",
      "         -7.8657e-03, -8.4207e-02, -5.6659e-02, -3.1062e-02,  0.0000e+00,\n",
      "          0.0000e+00, -3.0338e-02,  0.0000e+00, -1.3826e-02, -1.0517e-02,\n",
      "          0.0000e+00, -3.8151e-03, -5.1158e-02,  0.0000e+00],\n",
      "        [-3.8859e-05, -2.0222e-06,  0.0000e+00, -5.0886e-06, -4.3576e-05,\n",
      "          0.0000e+00,  0.0000e+00, -8.7477e-06,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -9.6099e-06, -3.1165e-05,  0.0000e+00, -1.4968e-05,\n",
      "          0.0000e+00,  0.0000e+00, -2.0479e-05,  0.0000e+00, -2.4602e-05,\n",
      "         -1.8769e-05,  0.0000e+00, -2.3598e-05, -2.6145e-05, -4.1114e-06,\n",
      "         -8.4684e-06, -7.1314e-06,  0.0000e+00,  0.0000e+00, -3.8880e-06,\n",
      "          0.0000e+00, -3.2348e-05, -3.4019e-05,  0.0000e+00,  0.0000e+00,\n",
      "         -3.6354e-05, -3.7154e-05,  0.0000e+00, -4.2188e-05,  0.0000e+00,\n",
      "          0.0000e+00, -4.0030e-05, -6.2955e-06, -6.0718e-06,  0.0000e+00,\n",
      "         -1.0423e-05, -1.6995e-05, -1.2964e-05,  0.0000e+00, -3.7404e-05,\n",
      "         -5.6994e-06, -4.5486e-05, -3.0656e-05, -1.7271e-05,  0.0000e+00,\n",
      "          0.0000e+00, -1.6303e-05,  0.0000e+00, -7.9084e-06, -5.7790e-06,\n",
      "          0.0000e+00, -2.4997e-06, -2.7247e-05,  0.0000e+00],\n",
      "        [ 2.8367e+00, -6.5660e-02,  0.0000e+00,  3.4252e-02,  3.1981e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.7577e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  5.0498e-01,  2.2061e+00,  0.0000e+00,  1.0032e+00,\n",
      "          0.0000e+00,  0.0000e+00,  1.4731e+00,  0.0000e+00,  1.8701e+00,\n",
      "          1.2628e+00,  0.0000e+00,  1.7038e+00,  2.0070e+00,  1.9506e-02,\n",
      "          6.0248e-01,  4.3833e-01,  0.0000e+00,  0.0000e+00,  5.6714e-02,\n",
      "          0.0000e+00,  2.5373e+00,  2.4403e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.5553e+00,  2.6375e+00,  0.0000e+00,  3.1546e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.9298e+00,  4.9002e-01,  3.0041e-01,  0.0000e+00,\n",
      "          6.2548e-01,  1.2217e+00,  9.2622e-01,  0.0000e+00,  2.7297e+00,\n",
      "          3.4380e-02,  3.2999e+00,  2.2108e+00,  1.1244e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.2048e+00,  0.0000e+00,  4.5868e-01,  3.9361e-01,\n",
      "          0.0000e+00,  6.6635e-02,  2.0778e+00,  0.0000e+00],\n",
      "        [-3.2241e-02, -1.1669e-03,  0.0000e+00, -3.4142e-03, -3.6195e-02,\n",
      "          0.0000e+00,  0.0000e+00, -7.1073e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -7.5023e-03, -2.5692e-02,  0.0000e+00, -1.2205e-02,\n",
      "          0.0000e+00,  0.0000e+00, -1.6939e-02,  0.0000e+00, -2.0589e-02,\n",
      "         -1.5315e-02,  0.0000e+00, -1.9533e-02, -2.1928e-02, -2.7390e-03,\n",
      "         -6.9884e-03, -5.7197e-03,  0.0000e+00,  0.0000e+00, -2.6818e-03,\n",
      "          0.0000e+00, -2.7260e-02, -2.8121e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -2.9926e-02, -3.0647e-02,  0.0000e+00, -3.5182e-02,  0.0000e+00,\n",
      "          0.0000e+00, -3.3230e-02, -5.2961e-03, -4.6955e-03,  0.0000e+00,\n",
      "         -8.3231e-03, -1.4055e-02, -1.0708e-02,  0.0000e+00, -3.1031e-02,\n",
      "         -3.8145e-03, -3.7689e-02, -2.5370e-02, -1.4002e-02,  0.0000e+00,\n",
      "          0.0000e+00, -1.3562e-02,  0.0000e+00, -6.2772e-03, -4.7270e-03,\n",
      "          0.0000e+00, -1.7965e-03, -2.2819e-02,  0.0000e+00],\n",
      "        [-3.4010e-01, -9.1474e-03,  0.0000e+00, -3.1016e-02, -3.8207e-01,\n",
      "          0.0000e+00,  0.0000e+00, -7.4043e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -7.6227e-02, -2.7000e-01,  0.0000e+00, -1.2742e-01,\n",
      "          0.0000e+00,  0.0000e+00, -1.7836e-01,  0.0000e+00, -2.1829e-01,\n",
      "         -1.5997e-01,  0.0000e+00, -2.0577e-01, -2.3277e-01, -2.4733e-02,\n",
      "         -7.3487e-02, -5.9117e-02,  0.0000e+00,  0.0000e+00, -2.4923e-02,\n",
      "          0.0000e+00, -2.9017e-01, -2.9601e-01,  0.0000e+00,  0.0000e+00,\n",
      "         -3.1422e-01, -3.2218e-01,  0.0000e+00, -3.7224e-01,  0.0000e+00,\n",
      "          0.0000e+00, -3.5065e-01, -5.6320e-02, -4.7414e-02,  0.0000e+00,\n",
      "         -8.5792e-02, -1.4798e-01, -1.1266e-01,  0.0000e+00, -3.2733e-01,\n",
      "         -3.4579e-02, -3.9727e-01, -2.6722e-01, -1.4569e-01,  0.0000e+00,\n",
      "          0.0000e+00, -1.4328e-01,  0.0000e+00, -6.4459e-02, -4.9446e-02,\n",
      "          0.0000e+00, -1.7233e-02, -2.4203e-01,  0.0000e+00]]), tensor([-2.3787e-02, -1.9502e-03, -3.3215e-01, -2.2952e-01, -1.0762e-03,\n",
      "        -1.4833e-02, -7.4853e-06,  6.8074e-01, -6.5320e-03, -7.0897e-02]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)  # the image size is 28 by 28\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "def Hv_computer(w, loss, v):\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        fristGrads = torch.autograd.grad(loss, w, create_graph=True)\n",
    "        fGv = [torch.dot(fG.flatten(), v.flatten()) for fG,v in zip(fristGrads, v)]\n",
    "        sums = torch.Tensor([0.])\n",
    "        for i in fGv:\n",
    "            sums = sums + i\n",
    "        return torch.autograd.grad([sums], w)\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    trainset = datasets.MNIST('', train=True, download=True, \n",
    "                           transform=transforms.Compose([\n",
    "                                    transforms.ToTensor()\n",
    "                                ]))\n",
    "    testset = datasets.MNIST('', train=False, download=True, \n",
    "                           transform=transforms.Compose([\n",
    "                                    transforms.ToTensor()\n",
    "                                ]))\n",
    "\n",
    "\n",
    "    trainloader  = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, pin_memory=True)\n",
    "    testloader  = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "    net = Net() # inital network\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)  # create a Adam optimizer\n",
    "\n",
    "    net.train() # set netowrk to traning mode\n",
    "    epochs = 2\n",
    "    for epoch in range(epochs):\n",
    "        for data in trainloader:\n",
    "            X, y = data\n",
    "            # training process\n",
    "            optimizer.zero_grad()    # clear the gradient calculated previously\n",
    "            predicted = net(X.view(-1, 28 * 28))  # put the mini-batch training data to Nerual Network, and get the predicted labels\n",
    "            loss = F.nll_loss(predicted, y)  # compare the predicted labels with ground-truth labels\n",
    "            loss.backward()      # compute the gradient\n",
    "            optimizer.step()     # optimize the network\n",
    "        print(f'epoch:{epoch}, loss:{loss}')\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    model.train()\" and \"model.eval()\" activates and deactivates Dropout and BatchNorm, so it is quite important. \n",
    "    \"with torch.no_grad()\" only deactivates gradient calculations, but doesn't turn off Dropout and BatchNorm.\n",
    "    Your model accuracy will therefore be lower if you don't use model.eval() when evaluating the model.\n",
    "    \"\"\"\n",
    "    net.eval() # evaluation mode\n",
    "\n",
    "    # Evaluation the trainig data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            X, y = data\n",
    "            output = net(X.view(-1, 28 * 28))\n",
    "            correct += (torch.argmax(output, dim=1) == y).sum().item() # 計算此次batch有多少預測正確；item()是將Tensor資料型態轉成 Python資料型態，否則Tensor型態無法與Python互相運算\n",
    "            total += y.size(0) # total加上每次batch數量\n",
    "\n",
    "    print(f'Training data Accuracy: {correct}/{total} = {round(correct/total, 3)}')\n",
    "\n",
    "    # Evaluation the testing data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            X, y = data\n",
    "            output = net(X.view(-1, 28 * 28))\n",
    "            correct += (torch.argmax(output, dim=1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    print(f'testing data Accuracy: {correct}/{total} = {round(correct/total, 3)}')\n",
    "\n",
    "    # -------------------------------------------------------------------------------------\n",
    "    X = testset[0][0]\n",
    "    y = torch.tensor([testset[0][1]])\n",
    "\n",
    "    output = net(X.view(-1, 28 * 28))\n",
    "    Error = F.nll_loss(output, y)\n",
    "    v = [torch.rand_like(p) for p in net.parameters()]\n",
    "    Hv = Hv_computer(list(net.parameters()), [Error], v)\n",
    "\n",
    "    print('shape of Hv: ',len(Hv))\n",
    "    for i in range(8):\n",
    "        print('layer ',i,' : ',Hv[i].size())\n",
    "    print('Hv:', Hv)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
