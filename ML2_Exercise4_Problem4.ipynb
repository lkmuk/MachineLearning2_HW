{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.optimize import minimize, Bounds\n",
    "\n",
    "import pylab as pl \n",
    "\n",
    "# ----------------------------------------------------------------------------        \n",
    "class dataset:\n",
    "    def __init__(self, numSamples=500, verbose=False):\n",
    "        digits = load_digits()\n",
    "        self.X = digits.data[:numSamples]\n",
    "        self.X /= np.max(self.X)\n",
    "        self.y = digits.target[:numSamples]\n",
    "        \n",
    "        if(verbose == True):\n",
    "            print(\"X looks like:\")\n",
    "            pl.gray()\n",
    "            pl.matshow(digits.images[0]) \n",
    "            pl.show()\n",
    "            print(\"X.shape:\", self.X.shape)\n",
    "            print(\"y.shape:\", self.y.shape)\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        return (self.X, self.y)\n",
    "# ----------------------------------------------------------------------------        \n",
    "def eval_model(data, gamma, C):\n",
    "    X, y = data\n",
    "    clf = SVC(C=C, gamma=gamma)\n",
    "    scores = cross_val_score(clf, X, y, cv=10)\n",
    "    return 1-np.mean(scores)\n",
    "\n",
    "# ----------------------------------------------------------------------------        \n",
    "class bayesian_optimization:\n",
    "    def __init__(self, data, numInitParams=20, verbose=False):\n",
    "        print(\"bayesian_optimization initialing......\")\n",
    "        \n",
    "        self.data = data\n",
    "        self.trainParams = self.get_random_new_params(numInitParams)\n",
    "        self.trainEvals = np.empty(self.trainParams.shape[0])\n",
    "        for i, (c, gamma) in enumerate(self.trainParams):\n",
    "            eval = eval_model(data, gamma, c)\n",
    "            self.trainEvals[i] = eval           \n",
    "        self.gp = GaussianProcessRegressor(kernel=RBF(), alpha=1e-4, normalize_y=True, n_restarts_optimizer=0, optimizer=None)\n",
    "        self.gp.fit(self.trainParams, self.trainEvals)\n",
    "        self.epsilon = 0.5\n",
    "        \n",
    "        if(verbose == True):\n",
    "            print(\"trainParams:\", self.trainParams)\n",
    "            print(\"trainEvals:\", self.trainEvals)\n",
    "        \n",
    "    def get_random_new_params(self, n):\n",
    "        cs = np.abs(np.random.normal(0, 5, size=n))\n",
    "        gammas = np.abs(np.random.normal(0, 1, size=n))\n",
    "        return np.stack([cs, gammas], axis=-1)\n",
    "    \n",
    "    def objective(self, x, epsilon):\n",
    "        # The objective function that should be minimized\n",
    "        x = x[np.newaxis, ...]\n",
    "        mean, std = self.gp.predict(x, return_std=True)\n",
    "        return mean - epsilon*std\n",
    "    \n",
    "    def select_next_test_params(self, epsilon=0.5, numNewParams=20):\n",
    "        # start the optimization from several random starting points, so we don't get stuck in a bad local optimum\n",
    "        starts = self.get_random_new_params(numNewParams)\n",
    "\n",
    "        # Keep the SVM parameters positive, otherwise the program will crash\n",
    "        bounds = Bounds(1e-7, np.inf, True)\n",
    "        best = float('inf')\n",
    "        best_param = np.empty(2, dtype=np.float64)\n",
    "        for start in starts:\n",
    "            # If no gradient function is supplied, it is estimated via finite differences\n",
    "            # in the optimization procedure\n",
    "            res = minimize(self.objective, start, epsilon, method='L-BFGS-B', bounds=bounds)\n",
    "            if res.fun < best:\n",
    "                best = res.fun\n",
    "                best_param = res.x\n",
    "\n",
    "        mean, std = self.gp.predict(best_param[np.newaxis, ...], return_std=True)\n",
    "\n",
    "        return best_param[0], best_param[1], mean[0], std[0]\n",
    "    \n",
    "    def start_optimizing(self, iteration=10):\n",
    "        for i in range(iteration):\n",
    "            new_c, new_gamma, pred_mean, pred_std = self.select_next_test_params(numNewParams=20)\n",
    "            print(f'Process selected c={new_c} and gamma={new_gamma}. Predicted mean={pred_mean}, std={pred_std}')\n",
    "            newParams = np.array([[new_c, new_gamma]])\n",
    "        \n",
    "            if np.any(np.all(np.abs(self.trainParams - newParams) <= 1e-7, axis=-1)):\n",
    "                print('Duplicate Detected, choosing random instead!')\n",
    "                newParams = self.get_random_new_params(1)\n",
    "                new_c, new_gamma = newParams[0]\n",
    "\n",
    "            eval = eval_model(self.data, new_gamma, new_c)\n",
    "            print(f'True CV Error is {eval}.')\n",
    "            self.trainParams = np.concatenate([self.trainParams, newParams], axis=0)\n",
    "            self.trainEvals = np.append(self.trainEvals, eval)\n",
    "            self.gp.fit(self.trainParams, self.trainEvals)\n",
    "        \n",
    "        final_c, final_gamma, mean, std = self.select_next_test_params(epsilon=0.5, numNewParams=20)\n",
    "        print(f'Process selected c={final_c} and gamma={final_gamma} as final parameters. Predicted mean={mean}, std={std}')\n",
    "        eval = eval_model(self.data, final_gamma, final_c)\n",
    "        print(f'True CV Error is {eval}.')\n",
    "\n",
    "# ----------------------------------------------------------------------------            \n",
    "if __name__ == '__main__':\n",
    "    ds = dataset(numSamples=500, verbose=True)\n",
    "    data = ds.get_dataset()\n",
    "        \n",
    "    ## you sould select random Cs and gammas and evaluate the CV error using the function eval_model above\n",
    "\n",
    "    ## here you create the evaluations data matrix with first and\n",
    "    ## second columns are gammas and Cs and the lst column is the true function evaluations at those gammas and Cs\n",
    "\n",
    "    bo = bayesian_optimization(data, numInitParams=20, verbose=True)\n",
    "    \n",
    "    ## Then you should call the select_next_test_point that you will implement and append the selected gamma and C as well as their evaluation\n",
    "    ## using eval_model to the evaluations matrix and repeat N times.\n",
    "    \n",
    "    ## Finally, select the point (gamma,C) that minimize the gaussian process prediction without caring about the standard deviation that is with epsilon  = 0\n",
    "    ## and evaluate it with eval_model and report (gamma,C) and gaussian process evaluation and the true evaluation of eval_model\n",
    "    bo.start_optimizing(100)\n",
    "    \n",
    "    print(bo.trainParams.shape)\n",
    "    print(bo.trainEvals.shape)\n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
